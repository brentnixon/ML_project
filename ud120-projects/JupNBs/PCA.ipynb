{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['eigenfaces.py']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.chdir('/Users/brentan/Documents/DAND/Week 13/ud120-projects/pca')\n",
    "os.getcwd()\n",
    "os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting the top 250 eigenfaces from 912 faces\n",
      "done in 0.139s\n",
      "Projecting the input data on the eigenfaces orthonormal basis\n",
      "done in 0.020s\n",
      "Fitting the classifier to the training set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/utils/deprecation.py:57: DeprecationWarning: Class RandomizedPCA is deprecated; RandomizedPCA was deprecated in 0.18 and will be removed in 0.20. Use PCA(svd_solver='randomized') instead. The new implementation DOES NOT store whiten ``components_``. Apply transform to get them.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 30.136s\n",
      "Best estimator found by grid search:\n",
      "SVC(C=1000.0, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma=0.0005, kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "Predicting the people names on the testing set\n",
      "done in 0.353s\n",
      "xtrain                    precision    recall  f1-score   support\n",
      "\n",
      "     Ariel Sharon       1.00      1.00      1.00        63\n",
      "     Colin Powell       1.00      1.00      1.00       171\n",
      "  Donald Rumsfeld       1.00      1.00      1.00        88\n",
      "    George W Bush       1.00      1.00      1.00       397\n",
      "Gerhard Schroeder       1.00      1.00      1.00        86\n",
      "       Tony Blair       1.00      1.00      1.00       107\n",
      "\n",
      "      avg / total       1.00      1.00      1.00       912\n",
      "\n",
      "\n",
      "\n",
      "xtest                    precision    recall  f1-score   support\n",
      "\n",
      "     Ariel Sharon       0.56      0.71      0.63        14\n",
      "     Colin Powell       0.83      0.80      0.81        65\n",
      "  Donald Rumsfeld       0.73      0.67      0.70        33\n",
      "    George W Bush       0.84      0.89      0.87       133\n",
      "Gerhard Schroeder       0.85      0.74      0.79        23\n",
      "       Tony Blair       0.88      0.78      0.83        37\n",
      "\n",
      "      avg / total       0.82      0.82      0.82       305\n",
      "\n",
      "[[ 10   2   2   0   0   0]\n",
      " [  2  52   1   9   0   1]\n",
      " [  3   1  22   6   0   1]\n",
      " [  3   3   3 119   3   2]\n",
      " [  0   2   0   4  17   0]\n",
      " [  0   3   2   3   0  29]]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "===================================================\n",
    "Faces recognition example using eigenfaces and SVMs\n",
    "===================================================\n",
    "\n",
    "The dataset used in this example is a preprocessed excerpt of the\n",
    "\"Labeled Faces in the Wild\", aka LFW_:\n",
    "\n",
    "  http://vis-www.cs.umass.edu/lfw/lfw-funneled.tgz (233MB)\n",
    "\n",
    "  .. _LFW: http://vis-www.cs.umass.edu/lfw/\n",
    "\n",
    "  original source: http://scikit-learn.org/stable/auto_examples/applications/face_recognition.html\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "# print(__doc__)\n",
    "\n",
    "# from time import time\n",
    "# import logging\n",
    "# import pylab as pl\n",
    "# import numpy as np\n",
    "\n",
    "# from sklearn.cross_validation import train_test_split\n",
    "# from sklearn.datasets import fetch_lfw_people\n",
    "# from sklearn.grid_search import GridSearchCV\n",
    "# from sklearn.metrics import classification_report\n",
    "# from sklearn.metrics import confusion_matrix\n",
    "# from sklearn.decomposition import RandomizedPCA\n",
    "# from sklearn.svm import SVC\n",
    "\n",
    "# # Display progress logs on stdout\n",
    "# logging.basicConfig(level=logging.INFO, format='%(asctime)s %(message)s')\n",
    "\n",
    "\n",
    "###############################################################################\n",
    "# Download the data, if not already on disk and load it as numpy arrays\n",
    "# lfw_people = fetch_lfw_people(min_faces_per_person=70, resize=0.4)\n",
    "\n",
    "# introspect the images arrays to find the shapes (for plotting)\n",
    "# n_samples, h, w = lfw_people.images.shape\n",
    "# np.random.seed(42)\n",
    "\n",
    "# # for machine learning we use the data directly (as relative pixel\n",
    "# # position info is ignored by this model)\n",
    "# X = lfw_people.data\n",
    "# n_features = X.shape[1]\n",
    "\n",
    "# # the label to predict is the id of the person\n",
    "# y = lfw_people.target\n",
    "# target_names = lfw_people.target_names\n",
    "# n_classes = target_names.shape[0]\n",
    "\n",
    "# print(\"Total dataset size:\")\n",
    "# print(\"n_samples: %d\" % n_samples)\n",
    "# print(\"n_features: %d\" % n_features)\n",
    "# print(\"n_classes: %d\" % n_classes)\n",
    "\n",
    "\n",
    "# ###############################################################################\n",
    "# # Split into a training and testing set\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "###############################################################################\n",
    "# Compute a PCA (eigenfaces) on the face dataset (treated as unlabeled\n",
    "# dataset): unsupervised feature extraction / dimensionality reduction\n",
    "\n",
    "n_components = 250\n",
    "\n",
    "# 10 -- 0.21\n",
    "# 15 -- 0.33\n",
    "# 25 -- 0.52\n",
    "# 50 -- 0.65\n",
    "# 100 -- 0.69\n",
    "# 150 - .67\n",
    "# 250 -- 0.61\n",
    "\n",
    "print(\"Extracting the top %d eigenfaces from %d faces\" % (n_components, X_train.shape[0]))\n",
    "t0 = time()\n",
    "pca = RandomizedPCA(n_components=n_components, whiten=True).fit(X_train)\n",
    "print(\"done in %0.3fs\" % (time() - t0))\n",
    "\n",
    "eigenfaces = pca.components_.reshape((n_components, h, w))\n",
    "\n",
    "print(\"Projecting the input data on the eigenfaces orthonormal basis\")\n",
    "t0 = time()\n",
    "X_train_pca = pca.transform(X_train)\n",
    "X_test_pca = pca.transform(X_test)\n",
    "print(\"done in %0.3fs\" % (time() - t0))\n",
    "\n",
    "\n",
    "pca.explained_variance_ratio_\n",
    "\n",
    "###############################################################################\n",
    "# Train a SVM classification model\n",
    "\n",
    "print(\"Fitting the classifier to the training set\")\n",
    "t0 = time()\n",
    "param_grid = {\n",
    "         'C': [1e3, 5e3, 1e4, 5e4, 1e5],\n",
    "          'gamma': [0.0001, 0.0005, 0.001, 0.005, 0.01, 0.1],\n",
    "          }\n",
    "# for sklearn version 0.16 or prior, the class_weight parameter value is 'auto'\n",
    "clf = GridSearchCV(SVC(kernel='rbf', class_weight='balanced'), param_grid)\n",
    "clf = clf.fit(X_train_pca, y_train)\n",
    "print(\"done in %0.3fs\" % (time() - t0))\n",
    "print(\"Best estimator found by grid search:\")\n",
    "print(clf.best_estimator_)\n",
    "\n",
    "\n",
    "###############################################################################\n",
    "# Quantitative evaluation of the model quality on the test set\n",
    "\n",
    "print(\"Predicting the people names on the testing set\")\n",
    "t0 = time()\n",
    "y_pred_train = clf.predict(X_train_pca)\n",
    "y_pred = clf.predict(X_test_pca)\n",
    "print(\"done in %0.3fs\" % (time() - t0))\n",
    "\n",
    "print(\"xtrain\", classification_report(y_train, y_pred_train, target_names=target_names))\n",
    "print(\"\\n\")\n",
    "print(\"xtest\", classification_report(y_test, y_pred, target_names=target_names))\n",
    "print(confusion_matrix(y_test, y_pred, labels=range(n_classes)))\n",
    "\n",
    "\n",
    "# ###############################################################################\n",
    "# # Qualitative evaluation of the predictions using matplotlib\n",
    "\n",
    "# def plot_gallery(images, titles, h, w, n_row=3, n_col=4):\n",
    "#     \"\"\"Helper function to plot a gallery of portraits\"\"\"\n",
    "#     pl.figure(figsize=(1.8 * n_col, 2.4 * n_row))\n",
    "#     pl.subplots_adjust(bottom=0, left=.01, right=.99, top=.90, hspace=.35)\n",
    "#     for i in range(n_row * n_col):\n",
    "#         pl.subplot(n_row, n_col, i + 1)\n",
    "#         pl.imshow(images[i].reshape((h, w)), cmap=pl.cm.gray)\n",
    "#         pl.title(titles[i], size=12)\n",
    "#         pl.xticks(())\n",
    "#         pl.yticks(())\n",
    "\n",
    "\n",
    "# # plot the result of the prediction on a portion of the test set\n",
    "\n",
    "# def title(y_pred, y_test, target_names, i):\n",
    "#     pred_name = target_names[y_pred[i]].rsplit(' ', 1)[-1]\n",
    "#     true_name = target_names[y_test[i]].rsplit(' ', 1)[-1]\n",
    "#     return 'predicted: %s\\ntrue:      %s' % (pred_name, true_name)\n",
    "\n",
    "# prediction_titles = [title(y_pred, y_test, target_names, i)\n",
    "#                          for i in range(y_pred.shape[0])]\n",
    "\n",
    "# plot_gallery(X_test, prediction_titles, h, w)\n",
    "\n",
    "# # plot the gallery of the most significative eigenfaces\n",
    "\n",
    "# eigenface_titles = [\"eigenface %d\" % i for i in range(eigenfaces.shape[0])]\n",
    "# plot_gallery(eigenfaces, eigenface_titles, h, w)\n",
    "\n",
    "# pl.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
